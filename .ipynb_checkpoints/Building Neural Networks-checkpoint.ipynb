{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Netweorks in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn.functional import sigmoid, softmax, relu\n",
    "import helper\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.input = nn.Linear(784,256)\n",
    "    \n",
    "        self.ouput = nn.Linear(256,10)\n",
    "    \n",
    "    def feedforward(self,x):\n",
    "        x = sigmoid(self.input(x))\n",
    "        x = softmax(self.ouput(x), dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_1 = nn.Linear(784, 128)\n",
    "        self.hidden_layer_2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = relu(self.hidden_layer_1(x))\n",
    "        x = relu(self.hidden_layer_2(x))\n",
    "        x = softmax(self.output_layer(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerNet(\n",
       "  (hidden_layer_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden_layer_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayerNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the weights & bias automatically generated for us when we used `nn.Linear` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0174, -0.0345, -0.0340,  ...,  0.0005, -0.0057, -0.0262],\n",
       "        [ 0.0242,  0.0298,  0.0130,  ...,  0.0213, -0.0014,  0.0110],\n",
       "        [ 0.0111, -0.0095, -0.0225,  ...,  0.0163, -0.0177,  0.0160],\n",
       "        ...,\n",
       "        [-0.0115,  0.0028, -0.0168,  ..., -0.0304, -0.0306, -0.0072],\n",
       "        [ 0.0022,  0.0319,  0.0121,  ..., -0.0200,  0.0212,  0.0286],\n",
       "        [ 0.0096,  0.0164,  0.0169,  ...,  0.0117,  0.0300, -0.0016]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_layer_1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0297, -0.0140,  0.0308, -0.0028, -0.0093, -0.0134,  0.0193,  0.0297,\n",
       "        -0.0131, -0.0075,  0.0348, -0.0145,  0.0238,  0.0355,  0.0322,  0.0042,\n",
       "        -0.0150, -0.0161,  0.0213,  0.0305, -0.0078, -0.0185, -0.0305, -0.0351,\n",
       "         0.0327,  0.0323,  0.0274,  0.0011,  0.0228,  0.0038,  0.0166, -0.0273,\n",
       "        -0.0274,  0.0058, -0.0146, -0.0160,  0.0049,  0.0001, -0.0176,  0.0136,\n",
       "         0.0209,  0.0299,  0.0178, -0.0102,  0.0329, -0.0320, -0.0193,  0.0116,\n",
       "        -0.0112,  0.0053,  0.0281,  0.0020, -0.0276,  0.0187, -0.0021, -0.0005,\n",
       "         0.0304,  0.0241, -0.0328,  0.0061,  0.0047, -0.0062,  0.0269,  0.0057,\n",
       "         0.0287,  0.0215, -0.0211,  0.0300,  0.0276,  0.0293,  0.0180,  0.0208,\n",
       "        -0.0337,  0.0327,  0.0229,  0.0194,  0.0325, -0.0305, -0.0005,  0.0185,\n",
       "         0.0003,  0.0168, -0.0305,  0.0241, -0.0238,  0.0076,  0.0338,  0.0069,\n",
       "         0.0115, -0.0192, -0.0320,  0.0137,  0.0214,  0.0231,  0.0278, -0.0112,\n",
       "         0.0058,  0.0288,  0.0294, -0.0295, -0.0198, -0.0346, -0.0284, -0.0126,\n",
       "        -0.0122,  0.0272, -0.0117,  0.0261,  0.0055, -0.0200, -0.0125, -0.0140,\n",
       "        -0.0307,  0.0222, -0.0224,  0.0071, -0.0250,  0.0303,  0.0155,  0.0334,\n",
       "         0.0145, -0.0134, -0.0312, -0.0031,  0.0097, -0.0004,  0.0339, -0.0192],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_layer_1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Initialization of Weights and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check the auto generated weights and bias using `model.hidden_layer_1.weight` & `model.hidden_layer_1.bias` we only get to see the _Autogard_ values. To modify these weights we need to get the real tensors representing the weights and bias using `model.hidden_layer_1.weight.data` & `model.hidden_layer_1.bias.data` as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0098,  0.0107, -0.0001,  ..., -0.0127, -0.0147, -0.0002],\n",
       "        [-0.0080,  0.0038,  0.0020,  ...,  0.0005,  0.0129, -0.0142],\n",
       "        [-0.0030, -0.0113,  0.0028,  ...,  0.0074,  0.0068,  0.0046],\n",
       "        ...,\n",
       "        [ 0.0113,  0.0040, -0.0173,  ..., -0.0006, -0.0061,  0.0128],\n",
       "        [ 0.0099, -0.0149,  0.0020,  ...,  0.0071,  0.0042, -0.0070],\n",
       "        [ 0.0077, -0.0088, -0.0131,  ...,  0.0059,  0.0079,  0.0091]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Weights normal random values with a standard deviation on 0.01\n",
    "model.hidden_layer_1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_layer_1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass an image to see how good the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images\n",
    "\n",
    "# Images location\n",
    "data_location = '/Users/philsamoei/projects/ML/udacity/scholarshipchallenge/deep-learning-v2-pytorch/data'\n",
    "data_location+'/MNIST_data'\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(data_location+'/MNIST_data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# images.resize_(64,1,784)\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "# images.resize_(64, 1, 784)\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "img_idx = 0\n",
    "\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "\n",
    "helper.view_classify(img.view(1,28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our model is not trained it does not understand the images its being shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we will use `nn.Sequential` to make it easier to build a network that we can pass the params sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = 784\n",
    "hidden_layers = [128, 64]\n",
    "output = 10\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    (\"hidden_layer1\", nn.Linear(input_layer, hidden_layers[0])),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"hidden_layer2\", nn.Linear(hidden_layers[0], hidden_layers[1])),\n",
    "    (\"relu2\", nn.ReLU()),\n",
    "    (\"output\", nn.Linear(hidden_layers[1], output)),\n",
    "    (\"softmax\", nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Grab some data for testing\n",
    "images, label = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass to get our logits/scores\n",
    "log_probabilities = model(images)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(log_probabilities, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_layer1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (hidden_layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=128, bias=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3297, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically calculates the gradients of tensors. It works by keeping track on operations performed on the tensors then it can go back while calculating the gradients, hence _Backpropagation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(1, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5440,  1.0209],\n",
       "        [-0.0572,  1.0329]], requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0881,  2.0419],\n",
       "        [-0.1145,  2.0658]], grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward at 0x128c08da0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2703, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any gradient so far for x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any gradient so far for y\n",
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any gradient so far for z\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the gradients run backwards on variable z\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have any gradient so far for x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have any gradient so far for y\n",
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass: \\n\", model.hidden_layer1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backward pass: \n",
      " tensor([[-0.0045, -0.0045, -0.0045,  ..., -0.0045, -0.0045, -0.0045],\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [-0.0044, -0.0044, -0.0044,  ..., -0.0044, -0.0044, -0.0044],\n",
      "        ...,\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011]])\n"
     ]
    }
   ],
   "source": [
    "print(\"After backward pass: \\n\", model.hidden_layer1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimaztion is updating the weights with the gradients\n",
    "\n",
    "The general process of training a network in pytorch is\n",
    "\n",
    "* Do a forward pass on the model\n",
    "* Calculate the loss from the forward pass\n",
    "* Calculate the gradients by performing a backward pass on the loss\n",
    "* Use the optimizer to update the weights using the calculated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: \n",
      " Parameter containing:\n",
      "tensor([[ 0.0330, -0.0051,  0.0234,  ...,  0.0317, -0.0270, -0.0156],\n",
      "        [ 0.0218,  0.0194, -0.0035,  ...,  0.0339,  0.0141, -0.0317],\n",
      "        [ 0.0230,  0.0000,  0.0037,  ...,  0.0035, -0.0303,  0.0281],\n",
      "        ...,\n",
      "        [ 0.0071,  0.0138, -0.0155,  ...,  0.0193,  0.0124,  0.0240],\n",
      "        [ 0.0262,  0.0158, -0.0113,  ..., -0.0257, -0.0249,  0.0147],\n",
      "        [-0.0061, -0.0006, -0.0127,  ...,  0.0345, -0.0206,  0.0248]],\n",
      "       requires_grad=True)\n",
      "Gradients: \n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
      "        [ 0.0001,  0.0001,  0.0001,  ...,  0.0001,  0.0001,  0.0001],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004]])\n",
      "Updated Weights: \n",
      " Parameter containing:\n",
      "tensor([[ 0.0330, -0.0051,  0.0234,  ...,  0.0317, -0.0270, -0.0156],\n",
      "        [ 0.0218,  0.0194, -0.0036,  ...,  0.0339,  0.0140, -0.0317],\n",
      "        [ 0.0230,  0.0000,  0.0037,  ...,  0.0035, -0.0302,  0.0281],\n",
      "        ...,\n",
      "        [ 0.0071,  0.0138, -0.0155,  ...,  0.0193,  0.0124,  0.0240],\n",
      "        [ 0.0262,  0.0158, -0.0113,  ..., -0.0257, -0.0249,  0.0147],\n",
      "        [-0.0062, -0.0006, -0.0127,  ...,  0.0345, -0.0206,  0.0248]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Weights: \\n\", model.hidden_layer1.weight)\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "# optimizers requires the paramters to update and the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "# Clear the gradients becuase for every backward pass its accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "log_probs = model(images)\n",
    "#calculate loss\n",
    "loss = criterion(log_probs, labels)\n",
    "#backward pass\n",
    "loss.backward()\n",
    "print(\"Gradients: \\n\", model.hidden_layer1.weight.grad)\n",
    "#update weights\n",
    "optimizer.step()\n",
    "print(\"Updated Weights: \\n\", model.hidden_layer1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Implemented neural network capable of predicting handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9292910637886032\n",
      "Training loss: 0.8607724097047025\n",
      "Training loss: 0.5315849918451137\n",
      "Training loss: 0.43674332333970933\n",
      "Training loss: 0.3917511620882478\n",
      "Training loss: 0.3648292372888848\n",
      "Training loss: 0.3458736185183022\n",
      "Training loss: 0.331572781509555\n",
      "Training loss: 0.3199742227586221\n",
      "Training loss: 0.30960311987665673\n",
      "Training loss: 0.300659416175918\n",
      "Training loss: 0.29250535643748893\n",
      "Training loss: 0.28458353981121515\n",
      "Training loss: 0.2772412703140204\n",
      "Training loss: 0.2703358804239139\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    (\"layer1\", nn.Linear(input_layer, hidden_layers[0])),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"layer2\", nn.Linear(hidden_layers[0], hidden_layers[1])),\n",
    "    (\"relu2\", nn.ReLU()),\n",
    "    (\"output_layer\", nn.Linear(hidden_layers[1], output)),\n",
    "    (\"softmax\", nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "# Define the cost function AKA loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Define the optimization strategy used to update the weights\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# Train the model for the number of epochs\n",
    "for e in range(epochs):\n",
    "    current_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten images\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do a forward pass\n",
    "        log_probabilities = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(log_probabilities, labels)\n",
    "        \n",
    "        # Generate the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Combine the loss for the bacth\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: {current_loss/len(trainloader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
